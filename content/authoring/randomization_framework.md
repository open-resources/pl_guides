# Randomization Framework

**Work on this framework was done in collaboration with CPSC 448 Directed Studies students Romina Mahinpei, Iris Xu, and Dr. Steve Wolfman and was presented at SIGCSE 2024 in Portland, Oregon.**
**The latest version of the framework can be found (and cited) [here](https://github.com/open-resources/randomization_framework/tree/main).**

The current version of our randomization framework classifies randomization into six levels ranging from 0 to 5.
Levels in this framework are **not** necessarily on a quality hierarchy from worst to best.
In fact, a question is allowed to belong to multiple levels. Questions of relatively higher complexity, such as multi-part questions with many question parameters, may have the potential for a mix of level 1-4 randomization. Further note that level 5 randomization (highlighted in italics) mainly applies to assessments since it requires entirely independent variants.

As an example, this can be achieved by implementing a large question bank from which the assessment questions for **each student** are randomly chosen.

| Level | Label                 | Description                                                                      | Purpose                                                                                                            | Example                                                                                                                                              |
|-------|-----------------------|----------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| 0     | Unrandomized          | Every student receives precisely the same question.                              | Classify questions that are not randomized at all.                                                                 | Abdallah uses a perfect binary tree to implement a small database system with 63 nodes. How many leaves will this tree have?                         |
| 1     | Surface Features      | Surface level features (e.g., names, colours, phrases) change for each variant.  | Increase cognitive load for students when they are pattern matching.                                               | \{\{ Abdallah \}\} uses a perfect binary tree with 63 nodes to implement a \{\{ small database system \}\}. How many leaves will this tree have?     |
| 2     | Conditions            | Within a single problem scenario, conditions and values change for each variant. | Offer opportunities for repeated retrieval practice and more productive group work.                                | Abdallah uses a perfect binary tree to implement a small database system with \{\{ 63 \}\} nodes. How many leaves will this tree have?               |
| 3     | Scenarios             | Problem scenarios change for each variant, assessing a single concept.           | Enable students to develop strategies, algorithms, and procedures to solve multiple problem scenarios.             | Abdallah uses an \{\{ unbalanced \}\} binary tree to implement a small database system with 63 nodes. What \{\{ max height \}\} will this tree have? |
| 4     | Concepts              | Randomized variations lead to assessment of different concepts.                  | Diversify question style so students need to synthesize knowledge across concepts and cannot easily pattern match. | Abdallah uses an \{\{ M-ary tree with $m=4$ \}\} to implement a small database system with 63 nodes. How many leaves will this tree have?            |
| *5*   | *Different Questions* | *Each question variant is entirely independent.*                                 | *Provide students with authentic re-assessment opportunities to demonstrate proficiency.*                          | *\{\{ Abdallah uses a perfect binary tree to implement a small database system with 63 nodes. How many leaves will this tree have? \}\}*             |

## Usage Table 

For instructors looking to design randomized computer-based questions for their courses, there are several considerations to keep in mind. 
Implementation complexity may increase with higher levels of randomization and each level of randomization introduces variable effects on the problem-solving approach, so it is important to align decisions with available resources and instructional goals.
The table below outlines these pedagogical and logistical considerations associated with each level of our [randomization framework](https://github.com/open-resources/randomization_framework/blob/main/framework.md).

| Level | Label               | Effect on Approach                                                                    | Example Features                                           | Pedagogical Considerations                                                                                                                                                 | Logistical Considerations                                                                                      |
|-------|---------------------|---------------------------------------------------------------------------------------|------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| L0    | Unrandomized        | N/A                                                                                   | N/A                                                        | <li>May result in students memorizing answers.</li>                                                                                                                        | <li>Offers weakest exam security.</li>                                                                         |
| L1    | Surface Features    | Students do not need to account for the feature in their approach.                    | Changing order of MC options, variable names               | <li>Helps students practice question understanding and extract important information.</li> <li>Tests student understanding on a specific type or pattern of question.</li> | <li>Discourages answer sharing within exam room.</li>                                                          |
| L2    | Conditions          | Students can reuse the exact same approach across question variants.                  | Changing initial values and states                         | <li>Helps students practice calculations and execute algorithms.</li> <li>Tests student understanding on a specific type or pattern of question</li>                       | <li>Discourages answer sharing within the exam room.</li>                                                      |
| L3    | Scenarios           | Students can use a similar approach with slight adjustments across question variants. | Giving different cases of the same algorithm               | <li>Modifies question scenarios to help students build critical thinking skills</li> <li>Tests student understanding of multiple scenarios within a concept</li>           | <li>Protects against meaningful information leak.</li> <li>May lead to a slight variance in difficulty. </li>  |
| L4    | Concepts            | Students have to use different approaches across question variants.                   | Asking about different data structures and implementations | <li>Modifies question concepts to help students build critical thinking skills.</li> <li>Tests student understanding of multiple concepts.</li>                            | <li>Protects against meaningful information leak.</li> <li>May lead to a moderate variance in difficulty </li> |
| L5    | Different Questions | N/A                                                                                   | N/A                                                        | <li>Enables multiple attempts of assessments</li>                                                                                                                          | <li>Offers strongest exam security.</li><li>May lead to a wide variance in difficulty.</li>                    |

## Decision Tree to categorize questions

To minimize potential disagreement between reviewers classifying the randomization levels present in a question, we developed a decision tree to guide reviewers during the application of our randomization framework.
The tree outlines sequential steps and poses relevant questions to facilitate the systematic application of the framework.
The levels within the framework are not mutually exclusive, allowing a single question to be associated with multiple levels based on the characteristics of its randomized features.
Consequently, the rating process is iterative, starting with the identification of all variable features within a question and then having each feature assigned to a specific randomization level.

<img src="https://github.com/open-resources/randomization_framework/blob/main/guides/decision-tree.png?raw=true">
